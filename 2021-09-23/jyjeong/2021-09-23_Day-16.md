# 2021.09.23, Day-16

추석 이후,

## **Chapter 4. 레플리케이션과 그 밖의 컨트롤러: 관리되는 파드 배포**

<hr>

## **4.1 파드를 안정적으로 유지하기**

- 쿠버네티스에 컨테이너 목록을 제공하면 해당 컨테이너를 클러스터 어딘가에서 계속 실행되도록 할 수 있다.
- 파드가 노드에 스케줄링되는 즉시, 해당 노드의 Kubelet은 파드의 컨테이너를 실행하고 파드가 존재하는 한 컨테이너가 계속 실행되도록 한다.

→ 컨테이너의 프로세스에 크래시가 발생하면 Kubelet이 컨테이너를 다시 시작한다.

- 100% 해결되지는 않는다. Ex) JVM OOM, Application Infinite Loop, Deadlock 등.
- 애플리케이션이 다시 시작되도록 하려면 애플리케이션 내부의 기능에 의존하지 말고 외부에서 애플리케이션의 상태를 체크해야한다.(이것이 **Liveness probe**)

### **4.1.1 Liveness Probe.**

쿠버네티스는 Liveness Probe를 통해 컨테이너가 살아 있는지 확인한다.

- HTTP GET Probe
- TCP 소켓 Probe
- Exec Probe

**#. Liveness Probe Definition**

```yaml
**apiVersion: extensions/v1beta1
kind: Deployment
metadata:
    labels:
    app: myapp
    name: appapppod
    .
    .
    .
       livenessProbe:
         httpGet:
           path: /com/livenessstatus
           port: 7080
           scheme: HTTPS
           httpHeaders:
           - name: Your_customer_header_if_any
             value: my_customer_header_value
         initialDelaySeconds: 120
         timeoutSeconds: 40
         periodSeconds: 90**
```

**→ Container가 종료된다는 의미는 완전히 새로운 컨테이너가 생성된다는 것이다. 동일한 컨테이너가 다시 시작되는 개념이 아니다.**

### **4.1.4 Liveness Probe 추가 속성 설정**

- initialDelaySeconds: 15

→ 쿠버네티스는 첫 번째 프로브 실행까지 15초를 대기한다.

- **애플리케이션 시작 시간을 고려해 초기 지연을 설정해야한다.**
- Pod Describe를 통해 종료 코드를 확인할 수 있다.
- 128+9(SIGKILL-비정상종료 By Kernel) / 128+15(SIGTERM-정상종료 By Process)

### **4.1.5 Liveness Probe 추가 속성 설정**

- 운영 환경에서 필수.
- 더 나은 Liveness Probe를 위해 특정 URL 경로에 요청하도록 구성해 애플리케이션 내 실행 중인 모든 주요 구성 요소가 살아 있는지, 응답이 있는지 확인하도록 구성한다.
- 애플리케이션의 내부만 체크하고, 외부 요인의 영향을 받지 않도록 해야 한다.
- **프론트엔드 웹서버의 Liveness Probe는 백엔드 데이터베이스 연결 실패에 대해 관여하면 안된다.**

→ **근본적인 원인이 데이터베이스에 있는 경우, 웹 서버 컨테이너를 재시작해도 해결할 수 없다.**

- 최대한 가벼워야 한다. Ex) JVM Exec Probe 대신 http get Probe를 사용하라.

<hr>

## **4.2 레플리케이션컨트롤러 소개**

- 쿠버네티스 리소스로서 파드가 항상 실행되도록 보장한다.
- 레플리케이션컨트롤러는 사라진 파드를 감지(API Server 감시)해 교체 파드를 생성한다.

### **4.2.1 Replication Controller 동작**

**#. 컨트롤러 조정 루프 소개**

- 정확한 수의 파드가 항상 레이블 셀렉터와 일치하는지 확인

**#. Replication Controller 세 가지 요소 이해**

- 레이블 셀렉터
- 레플리카 수
- 파드 템플릿

**#. 컨트롤러 레이블 셀렉터 변경 영향**

레이블 셀렉터를 변경해도 기존 파드에 영향을 미치지 않는다.

→ 그냥 기존 Pod에 대한 관리가 끊어지는 것으로 이해하면 됨

**#. 파드 템플릿 변경 영향**

파드 템플릿을 변경해도 기존 파드에 영향을 미치지 않는다.

→ 새로운 Pod가 생성될 때, 변경된 파드 템플릿을 통해 Pod를 생성한다.

### **4.2.4 Replication Controller 범위 안팎으로 파드 이동하기**

- Replication Controller는 레이블 셀렉터와 일치하는 파드만을 관리한다.
- 파드의 레이블을 변경하면 Controller의 범위에서 제거되거나 추가될 수 있다.

**#. 컨트롤러에서 파드를 제거하는 실제 사례**

- 특정 파드에서 오류가 발생한 상황에서 해당 Pod의 Label을 변경하여 Replication Controller Manage 에서 벗어나게 한다.
- 그럼 Replication Controller에서 새로운 Pod를 생성한다.
- 관리에서 벗어난 Pod는 그 자체로 디버그 or 문제를 재연하여 해결한다.(지림)

### **4.2.6 Pod 수평 스케일링**

- 파드 수를 늘리거나 줄이는 것은 Replication Controller 리소스의 replicas 필드 값을 변경하기만 하면 된다.
- kubectl scale rc ooooo —replicas=10
- kubectl edit rc ooooo → replicas 변경

### **4.2.7 Replication Controller 삭제**

- kubectl delete rc ooooo —cascade=false

→ 관리하는 pod는 삭제하지 않은 채 rc만 삭제 가능하며, 관리 rc만 사라진다.

- 다시 rc, replicaset등을 사용해 관리할 수 있다.

<hr>

## **4.3 레플리케이션컨트롤러 대신 레플리카셋 사용하기**

- 솔직히 별거 없다.
- 그냥 레플리케이션컨트롤러 Vs. 레플리카셋 이해하면 됨

### **4.3.1 Replication Controller Vs. Replica Set**

- 레플리카셋은 좀 더 풍부한 표현식을 사용하는 파드 셀렉터를 갖고 있다.
- 레플리카셋의 셀렉터는 특정 레이블이 없는 파드나 레이블의 값과 상관없이 특정 레이블의 키를 갖는 파드를 매칭할 수 있다.
- 레이블 키의 존재만으로 파드 매칭이 가능하다.

### **4.3.2 Replication Controller Vs. Replica Set**

- 특이사항 있음
- replicaset.yaml로 리소스를 생성할 때, apiVersion이 v1이 아님.

→ 이거 이해안되는데.. 공부하기

- rs를 약자로 씀.
- **selector: matchExpressions: - key: app / operator: In / values: -xxxx**

**#. Operator**

- In : 레이블의 값이 지정된 값 중 하나와 일치.
- NotIn : 레이블의 값이 지정된 값과 일치하지 않아야 함.
- Exists : 파드는 지정된 키를 가진 레이블이 포함돼야 함.(값은 중요하지 않음)
- DoesNotExist : 파드에 지정된 키를 가진 레이블이 포함돼 있지 않아야 함.

<hr>

## **4.4 데몬셋을 사용해 각 노드에서 정확히 한 개의 파드 실행하기**

- 클러스터의 모든 노드에, 노드당 하나의 파드만 실행되길 워나는 경우
- 시스템 수준의 작업을 수행하는 인프라 관련 파드

      **Ex) 로그 수집기와 리소스 모니터를 실행하려는 경우 / 쿠버네티스의 kube-proxy**

- **데몬셋에 의해 생성되는 파드는 타깃 노드가 이미 지정돼 있고 쿠버네티스 스케줄러를 건너뛰는 것**을 제외하면 이 오브젝트는 레플리케이션컨트롤러 또는 레플리카셋과 매우 유사하다.
- 데몬셋에는 복제본 수라는 개념이 없다.(개념상 없을 수 밖에 없음)
- 노드가 다운되면 데몬셋은 다른 곳에서 파드를 생성하지 않는다.
- 새 노드가 클러스터에 추가되면 데몬셋은 즉시 새 파드 인스턴스를 새 노드에 배포한다.
- **데몬셋이 관리하는 파드는 스케줄러와 무관하다.**
- 약자로 ds

### **4.4.2 데몬셋을 사용해 특정 노드에서만 파드를 실행하기**

- Default - 모든 Node에 파드를 배포한다.
- Pod Templete에 node-Selector 속성을 지정하면 특정 노드에만 파드가 배포된다.

      Ex) Node에 Label을 설정 → 데몬셋 작성(해당 레이블 노드만 선택) → 리소스 할당

- ssd-monitor-daemonset.yaml

      Ex) spec: nodeSelector: disk: ssd

→ 이 파드의 인스턴스는 disk=ssd 레이블이 있는 각 노드에 생성될 것

- 필요한 레이블을 노드에 추가하면 추가하자마자 즉시 파드 실행(감시)
- 노드에 레이블을 삭제하면 삭제 즉시 파드 삭제(감시)

<hr>

## **4.5 완료 가능한 단일 태스크를 수행하는 파드 실행**

- 완료 가능한 태스크(completable task)에서는 프로세스가 종료된 후에 다시 시작되지 않는다.
- 그냥 배치라고 생각하면 됨.
- 노드 장애 발생 시, 다른 노드로 다시 스케줄링
- 프로세스 장애 발생 시, 잡에서 컨테이너를 다시 시작할 것인지 설정 가능

**#. 궁금증**

1. Batch 를 순차적으로 실행해야 한다면 가능한가?

      (Process가 종속될 경우)

아무튼 인상깊은 부분은, 크론잡은 스케줄에 설정한 각 실행에 항상 하나의 잡만 생성하지만 두 개의 잡이 동시에 생성되거나 전혀 생성되지 않을 수 있다.

따라서, 멱등성 보장(한번 실행이 아니라 여러 번 실행해도 괜춘)

프로세스 독립성 보장(다음 번 잡 실행이 이전의 실행에서 완료했어야 하는 작업을 수행) 하는지 꼭 확인